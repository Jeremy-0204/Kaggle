{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import tempfile\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"/kaggle/input/UBC-OCEAN/train.csv\")\n",
    "test = pd.read_csv(r\"/kaggle/input/UBC-OCEAN/test.csv\")\n",
    "train_tma = train[train[\"is_tma\"] == True]\n",
    "train_no_tma = train[train[\"is_tma\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tma['img_id_ext'] = [str(i) + \".png\" for i in train_tma['image_id']]\n",
    "train_no_tma['img_id_ext'] = [str(i) + \"_thumbnail.png\" for i in train_no_tma['image_id']]\n",
    "test['img_id_ext'] = [str(i) + \"_thumbnail.png\" for i in test['image_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_tma, train_no_tma])\n",
    "train_df.sort_index(ascending = True, inplace = True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "image_label = train_df['label']\n",
    "le.fit(image_label)\n",
    "train_df['label'] = le.transform(image_label)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# class TrainDataset(Dataset):\n",
    "#     def __init__(self, df, root_path, train_thumbnails, train_images, transform = None):\n",
    "#         self.df = df\n",
    "#         self.root_path = root_path\n",
    "#         self.train_thumbnails = train_thumbnails\n",
    "#         self.train_images = train_images\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name = self.df.iloc[idx, -1]\n",
    "        \n",
    "#         if \"thumbnail\" in img_name:\n",
    "#             img_path = os.path.join(root_path + train_thumbnails, img_name)\n",
    "#         else:\n",
    "#             img_path = os.path.join(root_path + train_images, img_name)\n",
    "        \n",
    "#         img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "#         if self.transform:\n",
    "#             img = self.transform(img)\n",
    "        \n",
    "#         label = self.df.iloc[idx, 1]\n",
    "#         label = torch.tensor(label)\n",
    "#         return img, label\n",
    "\n",
    "# norm_mean = [0.485, 0.456, 0.406]\n",
    "# norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)), \n",
    "#     transforms.CenterCrop(224), \n",
    "#     transforms.RandomHorizontalFlip(p = 0.5), \n",
    "#     transforms.RandomVerticalFlip(p = 0.5),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(norm_mean, norm_std),\n",
    "# ])\n",
    "\n",
    "# valid_transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(norm_mean, norm_std),\n",
    "# ])\n",
    "\n",
    "# root_path = \"/kaggle/input/UBC-OCEAN/\"\n",
    "# train_thumbnails = \"train_thumbnails/\"\n",
    "# train_images = \"train_images/\"\n",
    "# test_thumbnails = \"test_thumbnails/\"\n",
    "# test_images = \"test_images/\"\n",
    "\n",
    "# dataset = TrainDataset(df = train_df, root_path = root_path, train_thumbnails = train_thumbnails, train_images = train_images, transform = train_transform)\n",
    "\n",
    "# train_ratio = 0.8\n",
    "# valid_ratio = 0.2\n",
    "\n",
    "# train_size = int(train_ratio * len(train_df))\n",
    "# valid_size = len(train_df) - train_size\n",
    "\n",
    "# dataset_train, dataset_valid = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "# train_dataloader = DataLoader(dataset_train, batch_size = 8, shuffle = False, num_workers = 5)\n",
    "# valid_dataloader = DataLoader(dataset_valid, batch_size = 8, shuffle = False, num_workers = 5)\n",
    "\n",
    "# dataiter = iter(train_dataloader)\n",
    "# images = next(dataiter)\n",
    "# images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, root_path, train_thumbnails, train_images, transform=None):\n",
    "        self.df = df\n",
    "        self.root_path = root_path\n",
    "        self.train_thumbnails = train_thumbnails\n",
    "        self.train_images = train_images\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx, -1]\n",
    "        \n",
    "        if \"thumbnail\" in img_name:\n",
    "            img_path = os.path.join(self.root_path + self.train_thumbnails, img_name)\n",
    "        else:\n",
    "            img_path = os.path.join(self.root_path + self.train_images, img_name)\n",
    "        \n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.df.iloc[idx, 1]\n",
    "        label = torch.tensor(label)\n",
    "        \n",
    "        return img, label, img_name  # Return img_name along with img and label\n",
    "\n",
    "\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.CenterCrop(224), \n",
    "    transforms.RandomHorizontalFlip(p = 0.5), \n",
    "    transforms.RandomVerticalFlip(p = 0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std),\n",
    "])\n",
    "\n",
    "root_path = \"/kaggle/input/UBC-OCEAN/\"\n",
    "train_thumbnails = \"train_thumbnails/\"\n",
    "train_images = \"train_images/\"\n",
    "test_thumbnails = \"test_thumbnails/\"\n",
    "test_images = \"test_images/\"\n",
    "\n",
    "dataset = TrainDataset(df=train_df, root_path=root_path, train_thumbnails=train_thumbnails, train_images=train_images, transform=train_transform)\n",
    "\n",
    "train_ratio = 0.8\n",
    "valid_ratio = 0.2\n",
    "\n",
    "train_size = int(train_ratio * len(train_df))\n",
    "valid_size = len(train_df) - train_size\n",
    "\n",
    "dataset_train, dataset_valid = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size = 8, shuffle = False, num_workers = 5)\n",
    "valid_dataloader = DataLoader(dataset_valid, batch_size = 8, shuffle = False, num_workers = 5)\n",
    "\n",
    "dataiter = iter(train_dataloader)\n",
    "images = next(dataiter)\n",
    "images[0].shape\n",
    "\n",
    "dataiter = iter(valid_dataloader)\n",
    "images, labels, image_names = next(dataiter)\n",
    "# Now, image_names contains the file names of the images in the validation set\n",
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pic(dataloader):\n",
    "    examples = enumerate(dataloader)\n",
    "    batch_idx, (example_data, example_targets) = next(examples)\n",
    "    classes = ('HGSC', 'LGSC', 'EC', 'CC', 'MC')\n",
    "    fig = plt.figure()\n",
    "    for i in range(5):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        img = example_data[i]\n",
    "        print('pic shape:', img.shape)\n",
    "        img = img.swapaxes(0, 1)\n",
    "        img = img.swapaxes(1, 2)\n",
    "        plt.imshow(img, interpolation = 'none')\n",
    "        plt.title(classes[example_targets[i].item()])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, model_type = \"resnet18\", freeze_convnets = False, single_layer = True, hidden_units = 32):\n",
    "    # Load pre_trained model\n",
    "    if model_type == \"resnet18\":\n",
    "        model = models.resnet18(pretrained = True)\n",
    "    elif model_type == \"resnet50\":\n",
    "        model = models.resnet50(pretrained = True)\n",
    "    elif model_type == \"resnet101\":\n",
    "        model = models.resnet101(pretrained = True)\n",
    "    elif model_type == \"resnet152\":\n",
    "        model = models.resnet152(pretrained = True)\n",
    "    else:\n",
    "        model = models.resnet18(pretrained = True)\n",
    "        \n",
    "    # Freeze the convnets\n",
    "    if freeze_convnets:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = false\n",
    "    \n",
    "    # Get the output dimension from the Conv block\n",
    "    num_ftrs = model.fc.in_features\n",
    "    \n",
    "    # Parameters of newly constructed modules have requires_grad + True by default\n",
    "    # Here the size of each output sample is set to num_classes\n",
    "    if single_layer:\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    else:\n",
    "        model.fc = nn.Sequential(\n",
    "                    nn.Linear(num_ftrs, hidden_units),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_units, num_classes)\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, loss, train_dataloader, valid_dataloader, device, batch_size, num_epoch, lr, lr_min, optim = 'sgd', init = True, scheduler_type = 'Cosine'):\n",
    "    def init_xavier(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "    \n",
    "    if init:\n",
    "        net.apply(init_xavier)\n",
    "    \n",
    "    print('training on:', device)\n",
    "    net.to(device)\n",
    "    \n",
    "    if optim == 'sgd':\n",
    "        optimizer = torch.optim.SGD((param for param in net.parameters() if param.requires_grad), lr = lr, weight_decay = 0)\n",
    "    elif optim == 'adam':\n",
    "        optimizer = torch.optim.Adam((param for param in net.parameters() if param.requires_grad), lr = lr, weight_decay = 1e-3)\n",
    "    elif optim == 'adamW':\n",
    "        optimizer = torch.optim.AdamW((param for param in net.parameters() if param.requires_grad), lr = lr, weight_decay = 0)\n",
    "    elif optim == 'ranger':\n",
    "        optimizer = torch.optim.Ranger((param for param in net.parameters() if param.requires_grad), lr = lr, weight_decay = 0)\n",
    "    \n",
    "    if scheduler_type == 'Cosine':\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max = num_epoch, eta_min = lr_min)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_access = []\n",
    "    eval_access = []\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"------Start of training round {}------\".format(epoch + 1))\n",
    "        \n",
    "        net.train()\n",
    "        train_acc = 0\n",
    "        \n",
    "        for batch in tqdm(train_dataloader, desc = 'Train'):\n",
    "            imgs, targets = batch\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = net(imgs)\n",
    "            \n",
    "            Loss = loss(output, targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            Loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, pred = output.max(1)\n",
    "            num_correct = (pred == targets).sum().item()\n",
    "            acc = num_correct / (batch_size)\n",
    "            train_acc += acc\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(\"epoch: {}, Loss: {}, Acc: {}\".format(epoch, Loss.item(), train_acc / len(train_dataloader)))\n",
    "        train_access.append(train_acc / len(train_dataloader))\n",
    "        train_losses.append(Loss.item())\n",
    "        \n",
    "        net.eval()\n",
    "        eval_loss = 0\n",
    "        eval_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, targets in valid_dataloader:\n",
    "                imgs = imgs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                output = net(imgs)\n",
    "                Loss = loss(output, targets)\n",
    "                _, pred = output.max(1)\n",
    "                num_correct = (pred == targets).sum().item()\n",
    "                eval_loss += Loss\n",
    "                acc = num_correct / imgs.shape[0]\n",
    "                eval_acc += acc\n",
    "                \n",
    "            eval_losses = eval_loss / (len(valid_dataloader))\n",
    "            eval_acc = eval_acc / (len(valid_dataloader))\n",
    "            if eval_acc > best_acc:\n",
    "                best_acc = eval_acc\n",
    "                torch.save(net.state_dict(), 'best_acc.pth')\n",
    "            eval_access.append(eval_acc)\n",
    "            print(\"Loss on the overall validation set: {}\".format(eval_losses))\n",
    "            print(\"Correctness on the overall validation set: {}\".format(eval_acc))\n",
    "        \n",
    "    return train_losses, train_access, eval_access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_access(train_losses, train_access, valid_access, num_epoch):\n",
    "    plt.plot(1 + np.arange(len(train_losses)), train_losses, linewidth = 1.5, linestyle = 'dashed', label = 'train_losses')\n",
    "    plt.plot(1 + np.arange(len(train_access)), train_access, linewidth = 1.5, linestyle = 'dashed', label = 'train_access')\n",
    "    plt.plot(1 + np.arange(len(eval_access)), eval_access, linewidth = 1.5, linestyle = 'dashed', label = 'eval_access')\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.xticks(range(1, 1 + num_epoch, 1))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pic(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = build_model(num_classes = 5, model_type = \"resnet50\", freeze_convnets = False, single_layer = True, hidden_units = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_access, eval_access = train(net, loss, train_dataloader, valid_dataloader, device, batch_size = 8, num_epoch = 20, lr = 3e-4, lr_min = 1e-4, optim = 'adam', init = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('HGSC', 'LGSC', 'EC', 'CC', 'MC')\n",
    "image_id = []\n",
    "label = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, targets, name in valid_dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        output = net(imgs)\n",
    "        _, pred = output.max(1)\n",
    "        pred = pred.tolist()\n",
    "        targets = targets.tolist()        \n",
    "        for idx, _ in enumerate(pred):\n",
    "            score = pred[idx]\n",
    "            target = targets[idx]\n",
    "            print(name[idx], classes[score], classes[target])\n",
    "        break\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
